# 前言
{: id="20210106092029-45eknz4"}

并发编程属于编程技能里的高阶技能，并发编程是迈向高级程序员必须掌握的，在学习并发编程之前，需要做好一些知识储备工作，本篇文章是总结了学习并发编程之前所需要了解的一些基本知识。
{: id="20210106092029-04ellu0"}

# 并发编程里的一些术语解释
{: id="20210106092029-wvijuul"}

### 进程
{: id="20210106092029-m81x3r8"}

**进程（Process）** 是指计算机中已运行的程序，是操作系统资源分配的基本单位。程序本身只是指令、数据及其组织形式的描述，进程才是程序（那些指令和数据）的真正运行实例。
{: id="20210106092029-u8d6tmq"}

**作用**：在最开始的时候，计算机没有操作系统，一台计算机在同一时刻只能运行一个程序，因此计算机的资源利用率会很低下。后来随着操作系统的发展，引入了进程这个概念，将计算机中运行的单个程序以及操作系统给该程序分配的资源（比如内存、I/O、处理器等）抽象为一个进程。有了进程以后，一台计算机可以“**同时**”运行多个程序，这样带来的好处是，加入程序 A 需要进行一些耗时的操作，比如读取文件，这时可以让其他程序运行，从而提升了资源利用率。
{: id="20210106092029-9ui7ifx"}

### 线程
{: id="20210106092029-xv8g8sn"}

**线程（Thread）** 是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以**并发**多个线程，每条线程并行执行不同的任务。
{: id="20210106092029-8yyuanb"}

### 并发
{: id="20210106092029-5lqznn6"}

**并发（concurrency）** 在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行，但任一个时刻点上只有一个程序在处理机上运行。
{: id="20210106092029-izqhxde"}

### 并行
{: id="20210106092029-d8k261m"}

**并行（Parallerl）** 在操作系统中是指，一组程序按独立异步的速度执行，无论从微观还是宏观，程序都是一起执行的
{: id="20210106092029-xdc7et0"}

### 并发和并行的区别
{: id="20210106092029-m8iw44u"}

并发和并行是即相似又有区别的两个概念，并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。在多道程序环境下，并发性是指在一段时间内宏观上有多个程序在同时运行，但在单处理机系统中，每一时刻却仅能有一道程序执行，故微观上这些程序只能是分时地交替执行。倘若在计算机系统中有多个处理机，则这些可以并发执行的程序便可被分配到多个处理机上，实现并行执行，即利用每个处理机来处理一个可并发执行的程序，这样，多个程序便可以同时执行。
{: id="20210106092029-l73y034"}

### 同步
{: id="20210106092029-ld7o9y4"}

按照顺序执行方法，一个方法执行完，再执行下一个方法。
{: id="20210106092029-xor2x1l"}

### 异步
{: id="20210106092029-rfrv4zc"}

在执行一个方法等待返回结果的这个过程里，可以执行其他方法。
{: id="20210106092029-re7g1zr"}

# 为什么要使用多线程
{: id="20210106092029-wdlmy80"}

在编程的时候，合理的使用多线程可以提升软件的性能，但是随之而来的就是一系列的并发问题。
{: id="20210106092029-ftfgwna"}

# 并发问题的根源
{: id="20210106092029-rmdrnjo"}

### 1. 缓存导致的可见性问题
{: id="20210106092029-tjhpa73"}

我们假设线程 A 和线程 B 同时开始执行，那么第一次都会将 count=0 读到各自的 CPU 缓存里，执行完 count+=1 之后，各自 CPU 缓存里的值都是 1，同时写入内存后，我们会发现内存中是 1，而不是我们期望的 2。
{: id="20210106092029-pqajbc2"}

### 2. 线程切换带来的原子性问题
{: id="20210106092029-6bg53bc"}

高级语言里一条语句往往需要多条 CPU 指令完成，例如 `count += 1`，至少需要三条 CPU 指令。
{: id="20210106092029-7yqm39n"}

- {: id="20210106092029-6f0gpyb"}指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
- {: id="20210106092029-egavg66"}指令 2：之后，在寄存器中执行 +1 操作；
- {: id="20210106092029-w4v5ffi"}指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。
{: id="20210106092029-z694qyv"}

### 3. 编译器优化带来的有序性问题
{: id="20210106092029-lwb3iwn"}

# Java 如何解决并发问题
{: id="20210106092029-37qvket"}

Java 提供了以下几种方式来解决并发问题
{: id="20210106092029-yzoxe02"}

### synchronized、 volatile、final 三个关键字
{: id="20210106092029-e7t9dfl"}

1. {: id="20210106092029-cfqefzi"}synchronized 块可以保证原子性和可见性。
2. {: id="20210106092029-3b3qlcs"}volatile 关键字修饰变量，保证该变量的可见性，即所有线程都能看到它的值
{: id="20210106092029-kswe4b4"}

### Happens-Before 规则
{: id="20210106092029-9ygz9gt"}

Happens-Before 并不是说前面一个操作发生在后续操作的前面，它真正要表达的是：前面一个操作的结果对后续操作是可见的
{: id="20210106092029-avejroe"}

##### 程序顺序规则
{: id="20210106092029-pze52x8"}

这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作也就是说即程序前面对某个变量的修改一定是对后续操作可见的。
{: id="20210106092029-2xz4o76"}

##### volatile 变量规则
{: id="20210106092029-m0f2smu"}

对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。
{: id="20210106092029-ybr4yu0"}

##### 传递性
{: id="20210106092029-geuc5nx"}

如果 A happens-before B，且 B happens-before C，那么 Ahappens-before C。
{: id="20210106092029-zlg7uau"}

##### 管程中锁的规则
{: id="20210106092029-2b5oruh"}

这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。
{: id="20210106092029-344y9aj"}

##### 线程 start() 规则
{: id="20210106092029-pvncgvp"}

这条是关于线程启动的。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。换句话说就是，如果线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作
{: id="20210106092029-2zdhnit"}

##### 线程 join() 规则
{: id="20210106092029-guc9fre"}

这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作。换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回
{: id="20210106092029-bw8jo9z"}

# 安全性、活跃性以及性能问题
{: id="20210106092029-xofq43b"}

### 安全性
{: id="20210106092029-a9yjtxq"}

相信你一定听说过类似这样的描述：这个方法不是线程安全的，这个类不是线程安全的，等等。那什么是线程安全呢？其实本质上就是正确性，而正确性的含义就是程序按照我们期望的执行，不要让我们感到意外。
{: id="20210106092029-w6e4oet"}

面对数据竞争和竞态条件问题，又该如何保证线程的安全性呢？其实这两类问题，都可以用互斥这个技术方案，而实现互斥的方案有很多，CPU 提供了相关的互斥指令，操作系统、编程语言也会提供相关的 API。从逻辑上来看，我们可以统一归为：锁
{: id="20210106092029-xvn0vhc"}

### 活跃性
{: id="20210106092029-brymvzy"}

所谓活跃性问题，指的是某个操作无法执行下去。我们常见的“死锁”就是一种典型的活跃性问题，当然除了死锁外，还有两种情况，分别是“活锁”和“饥饿”。
{: id="20210106092029-5aolhbf"}

##### 死锁
{: id="20210106092029-rnyadbc"}

死锁”后线程会互相等待，而且会一直等待下去，在技术上的表现形式是线程永久地“阻塞”了。
{: id="20210106092029-sbkcesc"}

并发程序一旦死锁，一般没有特别好的方法，很多时候我们只能重启应用。因此，解决死锁问题最好的办法还是规避死锁。
{: id="20210106092029-ni3tl45"}

那如何避免死锁呢？要避免死锁就需要分析死锁发生的条件，有个叫 Coffman 的牛人早就总结过了，只有以下这四个条件都发生时才会出现死锁：
{: id="20210106092029-st2zmou"}

- {: id="20210106151513-6mn0h9b"}互斥，共享资源 X 和 Y 只能被一个线程占用；
- {: id="20210106151516-horwb1p"}占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
- {: id="20210106151520-8jx7v8a"}不可抢占，其他线程不能强行抢占线程 T1 占有的资源；
- {: id="20210106151523-a84cly8"}循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。
{: id="20210106151511-wj5pkrz"}

**反过来分析，也就是说只要我们破坏其中一个，就可以成功避免死锁的发生。**
{: id="20210106092029-hnpw7dj"}

其中，互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。
{: id="20210106092029-k0n8s62"}

##### 活锁
{: id="20210106092029-kf0kduv"}

有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”。可以类比现实世界里的例子，路人甲从左手边出门，路人乙从右手边进门，两人为了不相撞，互相谦让，路人甲让路走右手边，路人乙也让路走左手边，结果是两人又相撞了。这种情况，基本上谦让几次就解决了，因为人会交流啊。可是如果这种情况发生在编程世界了，就有可能会一直没完没了地“谦让”下去，成为没有发生阻塞但依然执行不下去的“活锁”。
{: id="20210106092029-szj3u2l"}

**解决“活锁”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。**
{: id="20210106092029-79k5zrz"}

##### 饥饿
{: id="20210106092029-k2vtc7y"}

所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况。“不患寡，而患不均”，如果线程优先级“不均”，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。
{: id="20210106092029-ujerdlz"}

解决“饥饿”问题的方案很简单，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些。
{: id="20210106092029-jz34r3w"}

那如何公平地分配资源呢？在并发编程里，主要是使用公平锁。所谓公平锁，是一种先来后到的方案，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。
{: id="20210106092029-w437j74"}

# 参考
{: id="20210106092029-q62ixfn"}

1. {: id="20210106092029-qovo1fq"}[codercc-并发编程](https://www.codercc.com/backend/basic/juc/)
2. {: id="20210106092029-65hg51b"}[java 并发编程体系](https://www.pdai.tech/md/java/thread/java-thread-x-overview.html)
{: id="20210106092029-ebg8vvo"}
